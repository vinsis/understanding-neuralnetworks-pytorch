## Understanding nuts and bolts of neural networks with PyTorch

__(Work in progress)__

This is a series of articles in an attempt to understand the witchcraft that is the neural networks (using PyTorch).

### Basic

* [__Gradient descent and various ways to implement it in PyTorch__](https://github.com/vinsis/understanding-neuralnetworks-pytorch/blob/master/markdowns/basics.md)

* [__Dropout__](https://github.com/vinsis/understanding-neuralnetworks-pytorch/blob/master/markdowns/dropout.md)

* [__Batch normalization__](https://github.com/vinsis/understanding-neuralnetworks-pytorch/blob/master/markdowns/batchnorm.md)

* [__Backpropagation and detach__](https://github.com/vinsis/understanding-neuralnetworks-pytorch/blob/master/markdowns/backprop.md)

* [__Losses in PyTorch__](https://github.com/vinsis/understanding-neuralnetworks-pytorch/blob/master/markdowns/Understanding%20losses.md)

* [__register_buffer__](https://github.com/vinsis/understanding-neuralnetworks-pytorch/blob/master/markdowns/register_buffer.md)

### Intermediate

* [__Groups in convolution__](https://github.com/vinsis/understanding-neuralnetworks-pytorch/blob/master/markdowns/groups.md)

* [__Hooks__](https://github.com/vinsis/understanding-neuralnetworks-pytorch/blob/master/markdowns/hooks.md)

* [__Weight normalization__](https://github.com/vinsis/understanding-neuralnetworks-pytorch/blob/master/markdowns/weightnorm.md)

* [__Einstein summation__](https://github.com/vinsis/understanding-neuralnetworks-pytorch/blob/master/markdowns/einstein_summation.md)

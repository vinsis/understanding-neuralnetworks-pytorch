## Understanding nuts and bolts of neural networks with PyTorch

__(Work in progress)__

This is a series of articles in an attempt to understand the witchcraft that is the neural networks (using PyTorch).

### Basic

* [__Dropout__](https://github.com/vinsis/understanding-neuralnetworks-pytorch/blob/master/dropout.md)

* [__Batch normalization__](https://github.com/vinsis/understanding-neuralnetworks-pytorch/blob/master/batchnorm.md)

* [__Backpropagation and detach__](https://github.com/vinsis/understanding-neuralnetworks-pytorch/blob/master/backprop.md)

* [__Losses in PyTorch__](https://github.com/vinsis/understanding-neuralnetworks-pytorch/blob/master/Understanding%20losses.md)

### Intermediate

* [__Groups in convolution__](https://github.com/vinsis/understanding-neuralnetworks-pytorch/blob/master/groups.md)

* [__Hooks__](https://github.com/vinsis/understanding-neuralnetworks-pytorch/blob/master/hooks.md)

* [__Weight normalization__](https://github.com/vinsis/understanding-neuralnetworks-pytorch/blob/master/weightnorm.md)
